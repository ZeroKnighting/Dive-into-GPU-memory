{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "定义获取显存占用的函数，返回总占用和当前行为占用"
      ],
      "metadata": {
        "id": "yXpkxCYojeJB"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jNPYJD7R0Qd7",
        "outputId": "9912cfb3-1fcd-49c5-a3a7-195c8c45390c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(0.0, 0.0)\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "import torch.nn.functional as F\n",
        "\n",
        "last_gpu_memory = 0\n",
        "\n",
        "def get_memory():\n",
        "  global last_gpu_memory\n",
        "  last = last_gpu_memory\n",
        "  now = torch.cuda.memory_allocated()/1024/1024\n",
        "  last_gpu_memory = now\n",
        "  return now,now-last\n",
        "print(get_memory())"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "用于分析显存占用的模型，包括三个线性层，一个激活层，一个softmax层"
      ],
      "metadata": {
        "id": "PBrdpMySjqA5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class BasicModel(torch.nn.Module):\n",
        "  def __init__(self):\n",
        "    super().__init__()\n",
        "    self.lr1 = torch.nn.Linear(1024,1024)\n",
        "    self.relu = torch.nn.ReLU()\n",
        "    self.lr2 = torch.nn.Linear(1024,1024)\n",
        "    self.sof = torch.nn.Softmax(dim = -1)\n",
        "    self.lr3 = torch.nn.Linear(1024,2048)\n",
        "\n",
        "  def forward(self,x):\n",
        "    x = self.lr1(x)\n",
        "    x = self.relu(x)\n",
        "    x = self.lr2(x)\n",
        "    x = self.sof(x)\n",
        "    x = self.lr3(x)\n",
        "    return x\n"
      ],
      "metadata": {
        "id": "BvqR9jx90c0N"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "测试模型参数占用"
      ],
      "metadata": {
        "id": "2dQ5IyuLjz7E"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = BasicModel().to('cuda')\n",
        "print('mymodel: ',get_memory())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2dxguW--1CgV",
        "outputId": "6eda05d2-3313-41d7-89e9-41648f535c87"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "mymodel:  (16.015625, 16.015625)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "测试输入数据占用"
      ],
      "metadata": {
        "id": "BMz3GqSoj3J_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "data = torch.zeros(10240,1024).to('cuda')\n",
        "print('input: ',get_memory())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Qp22mGxq36A4",
        "outputId": "f23ef0dc-75bb-4e6b-92eb-a0c3f20442e1"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "input:  (56.015625, 40.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "测试输出以及中间激活值占用"
      ],
      "metadata": {
        "id": "WfryX4qRj5NB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "out = model(data)\n",
        "print(\"output and intermediate: \",get_memory())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Nm5fmBUh37nU",
        "outputId": "a34860d0-1830-4d8c-a72c-cfe157be4345"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "output and intermediate:  (224.140625, 168.125)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "显存按页分配，最低分配512字节"
      ],
      "metadata": {
        "id": "kuAffdZHj9uX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "loss = torch.sum(out)\n",
        "print(\"loss: \",get_memory())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OYHKKl_x4QjQ",
        "outputId": "35e01a04-a5b5-431c-ee35-eb5dbcefd4b2"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "loss:  (224.14111328125, 0.00048828125)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "反向传播显存占用"
      ],
      "metadata": {
        "id": "ZbDg2uLwkDVR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "loss.backward()\n",
        "print(\"after backward: \",get_memory())\n",
        "torch.cuda.max_memory_allocated()/1024/1024"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3zj3slpm_VRo",
        "outputId": "8c6ca350-da21-4a9b-9ee0-6b70cf525add"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "after backward:  (168.28173828125, -55.859375)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "360.2744140625"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "优化器参数占用"
      ],
      "metadata": {
        "id": "TgWJ9cHckGm5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch.optim as optim\n",
        "optimizer = optim.AdamW(model.parameters())\n",
        "optimizer.step()\n",
        "print(\"optimizer: \",get_memory())\n",
        "torch.cuda.max_memory_allocated()/1024/1024"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lZgpDXyT-5HN",
        "outputId": "72d03a39-1ef0-4a87-b43b-35d7fba43bf0"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "optimizer:  (200.31298828125, 32.03125)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "360.2744140625"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    }
  ]
}