{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "定义获取显存占用的函数，返回总占用和当前行为占用"
      ],
      "metadata": {
        "id": "FY4s_evpkNh_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn.functional as F\n",
        "\n",
        "last_gpu_memory = 0\n",
        "\n",
        "def get_memory():\n",
        "  global last_gpu_memory\n",
        "  last = last_gpu_memory\n",
        "  now = torch.cuda.memory_allocated()/1024/1024\n",
        "  last_gpu_memory = now\n",
        "  return now,now-last\n",
        "print(get_memory())\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JN6J2yW634_-",
        "outputId": "5c169946-13ff-492e-bf48-73e86a465051"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(0.0, 0.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "用于分析显存占用的模型，包括三个线性层，一个激活层，一个softmax层"
      ],
      "metadata": {
        "id": "Fj59jyAokQtp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class BasicModel(torch.nn.Module):\n",
        "  def __init__(self):\n",
        "    super().__init__()\n",
        "    self.lr1 = torch.nn.Linear(1024,1024)\n",
        "    self.relu = torch.nn.ReLU()\n",
        "    self.lr2 = torch.nn.Linear(1024,1024)\n",
        "    self.sof = torch.nn.Softmax(dim = -1)\n",
        "    self.lr3 = torch.nn.Linear(1024,2048)\n",
        "\n",
        "  def forward(self,x):\n",
        "    x = self.lr1(x)\n",
        "    x = self.relu(x)\n",
        "    x = self.lr2(x)\n",
        "    x = self.sof(x)\n",
        "    x = self.lr3(x)\n",
        "    return x"
      ],
      "metadata": {
        "id": "7glO3U5SLnoT"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "测试推断阶段显存占用"
      ],
      "metadata": {
        "id": "eotpk057kSkT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "with torch.no_grad():\n",
        "  model = BasicModel().cuda()\n",
        "  print('mymodel: ',get_memory())\n",
        "  data = torch.zeros(10240,1024).to('cuda')\n",
        "  print('input: ',get_memory())\n",
        "  out = model(data)\n",
        "  print(\"output and intermediate: \",get_memory())\n",
        "print(torch.cuda.max_memory_allocated()/1024/1024)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VRg0vlgTLpQL",
        "outputId": "9a25b278-db01-48d3-82d4-2d5c4c6dba97"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "mymodel:  (16.015625, 16.015625)\n",
            "input:  (56.015625, 40.0)\n",
            "output and intermediate:  (144.140625, 88.125)\n",
            "185.140625\n"
          ]
        }
      ]
    }
  ]
}